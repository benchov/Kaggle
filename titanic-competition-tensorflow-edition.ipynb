{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-30T10:08:18.473500Z","iopub.execute_input":"2022-09-30T10:08:18.474044Z","iopub.status.idle":"2022-09-30T10:08:18.510237Z","shell.execute_reply.started":"2022-09-30T10:08:18.473941Z","shell.execute_reply":"2022-09-30T10:08:18.508917Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### IMPORTS","metadata":{}},{"cell_type":"code","source":"# feature engineering libs\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\n\n# sklearn \nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\n# tensorflow related libs\nimport tensorflow as tf\nfrom tensorflow.keras.layers import IntegerLookup, Normalization, StringLookup ","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:18.512795Z","iopub.execute_input":"2022-09-30T10:08:18.513238Z","iopub.status.idle":"2022-09-30T10:08:26.472380Z","shell.execute_reply.started":"2022-09-30T10:08:18.513203Z","shell.execute_reply":"2022-09-30T10:08:26.471197Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 500)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.473902Z","iopub.execute_input":"2022-09-30T10:08:26.474524Z","iopub.status.idle":"2022-09-30T10:08:26.480234Z","shell.execute_reply.started":"2022-09-30T10:08:26.474490Z","shell.execute_reply":"2022-09-30T10:08:26.478566Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### HELPER FUNCTIONS","metadata":{}},{"cell_type":"code","source":"def create_model_checkpoint(model_name, save_path=\"model_experiment\"):\n    return tf.keras.callbacks.ModelCheckpoint(\n        filepath=os.path.join(save_path, model_name), \n        verbose=1, \n        save_best_only=True,\n        monitor='val_accuracy',\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.484308Z","iopub.execute_input":"2022-09-30T10:08:26.485115Z","iopub.status.idle":"2022-09-30T10:08:26.510217Z","shell.execute_reply.started":"2022-09-30T10:08:26.485049Z","shell.execute_reply":"2022-09-30T10:08:26.509126Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def dataframe_to_dataset (dataframe, is_test):\n    data_frame = dataframe.copy()\n    if is_test:\n        ds = tf.data.Dataset.from_tensors(dict(data_frame))\n    else:    \n        labels = data_frame.pop(\"Survived\")\n        ds = tf.data.Dataset.from_tensor_slices((dict(data_frame), labels))\n        ds = ds.shuffle(buffer_size=len(data_frame))\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.511876Z","iopub.execute_input":"2022-09-30T10:08:26.512286Z","iopub.status.idle":"2022-09-30T10:08:26.520089Z","shell.execute_reply.started":"2022-09-30T10:08:26.512255Z","shell.execute_reply":"2022-09-30T10:08:26.519003Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def encode_numerical_feature (feature, name, dataset):\n    normalizer = Normalization()\n    \n    feature_ds = dataset.map(lambda x, y: x[name])\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n    \n    normalizer.adapt(feature_ds)\n    encoded_feature = normalizer(feature)\n    return encoded_feature","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.521369Z","iopub.execute_input":"2022-09-30T10:08:26.522412Z","iopub.status.idle":"2022-09-30T10:08:26.532712Z","shell.execute_reply.started":"2022-09-30T10:08:26.522377Z","shell.execute_reply":"2022-09-30T10:08:26.531637Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def encode_categorical_feature (feature, name, dataset, is_string):\n    lookup_class = StringLookup if is_string else IntegerLookup\n    lookup = lookup_class(output_mode=\"binary\")\n    \n    feature_ds = dataset.map(lambda x, y: x[name])\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n    \n    lookup.adapt(feature_ds)\n    encoded_feature = lookup(feature)\n    return encoded_feature","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.534155Z","iopub.execute_input":"2022-09-30T10:08:26.534536Z","iopub.status.idle":"2022-09-30T10:08:26.547517Z","shell.execute_reply.started":"2022-09-30T10:08:26.534502Z","shell.execute_reply":"2022-09-30T10:08:26.546509Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.549054Z","iopub.execute_input":"2022-09-30T10:08:26.549714Z","iopub.status.idle":"2022-09-30T10:08:26.558506Z","shell.execute_reply.started":"2022-09-30T10:08:26.549653Z","shell.execute_reply":"2022-09-30T10:08:26.557125Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### MANAGING DATA","metadata":{}},{"cell_type":"code","source":"# Imports dataset from Kaggle\ntrain_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nlen(train_df), len(test_df), train_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.560020Z","iopub.execute_input":"2022-09-30T10:08:26.560379Z","iopub.status.idle":"2022-09-30T10:08:26.597169Z","shell.execute_reply.started":"2022-09-30T10:08:26.560340Z","shell.execute_reply":"2022-09-30T10:08:26.596018Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(891, 418, (891, 12), (418, 11))"},"metadata":{}}]},{"cell_type":"code","source":"print(train_df.info())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.601119Z","iopub.execute_input":"2022-09-30T10:08:26.602090Z","iopub.status.idle":"2022-09-30T10:08:26.650290Z","shell.execute_reply.started":"2022-09-30T10:08:26.602044Z","shell.execute_reply":"2022-09-30T10:08:26.649116Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nNone\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### CLEANING DATA","metadata":{}},{"cell_type":"code","source":"print(train_df.isna().sum())\nprint(test_df.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.652035Z","iopub.execute_input":"2022-09-30T10:08:26.653345Z","iopub.status.idle":"2022-09-30T10:08:26.665301Z","shell.execute_reply.started":"2022-09-30T10:08:26.653294Z","shell.execute_reply":"2022-09-30T10:08:26.664031Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Filling age column missing values\ntrain_df[\"Age\"] = train_df.groupby([\"Sex\", \"Pclass\"])[\"Age\"].apply(lambda x: x.fillna(x.median()))\ntest_df[\"Age\"] = test_df.groupby([\"Sex\", \"Pclass\"])[\"Age\"].apply(lambda x: x.fillna(x.median()))\n\n# Filling embarked column missing values\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna('S')\ntest_df[\"Embarked\"] = test_df[\"Embarked\"].fillna('S')\n\n# Filling fare column missing values\nmedian_fare_value = train_df.groupby([\"Pclass\", \"SibSp\", \"Parch\"])[\"Fare\"].median()[3][0][0]\ntrain_df[\"Fare\"] = train_df[\"Fare\"].fillna(median_fare_value)\ntest_df[\"Fare\"] = test_df[\"Fare\"].fillna(median_fare_value)\n\n# Creating deck column based on cabin column\ntrain_df[\"Deck\"] = train_df[\"Cabin\"].apply(lambda s: s[0] if pd.notnull(s) else 'M')\ntest_df[\"Deck\"] = test_df[\"Cabin\"].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\ntrain_df[\"Deck\"] = train_df[\"Deck\"].replace(['A','B','C', 'T'], 'ABC')\ntrain_df[\"Deck\"] = train_df[\"Deck\"].replace(['D','E'], 'DE')\ntrain_df[\"Deck\"] = train_df[\"Deck\"].replace(['F','G'], 'FG')\n \ntest_df[\"Deck\"] = test_df[\"Deck\"].replace(['A','B','C', 'T'], 'ABC')\ntest_df[\"Deck\"] = test_df[\"Deck\"].replace(['D','E'], 'DE')\ntest_df[\"Deck\"] = test_df[\"Deck\"].replace(['F','G'], 'FG')","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.666782Z","iopub.execute_input":"2022-09-30T10:08:26.667551Z","iopub.status.idle":"2022-09-30T10:08:26.711326Z","shell.execute_reply.started":"2022-09-30T10:08:26.667516Z","shell.execute_reply":"2022-09-30T10:08:26.709577Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Binning continous features\ntrain_df[\"Fare\"] = pd.qcut(train_df[\"Fare\"], 13)\ntest_df[\"Fare\"] = pd.qcut(test_df[\"Fare\"], 13)\n\ntrain_df[\"Age\"] = pd.qcut(train_df[\"Age\"], 10)\ntest_df[\"Age\"] = pd.qcut(test_df[\"Age\"], 10)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.712689Z","iopub.execute_input":"2022-09-30T10:08:26.713001Z","iopub.status.idle":"2022-09-30T10:08:26.745190Z","shell.execute_reply.started":"2022-09-30T10:08:26.712972Z","shell.execute_reply":"2022-09-30T10:08:26.744056Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Frequency Encoding\ntrain_df[\"Family_Size\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntest_df[\"Family_Size\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n\ntrain_df[\"Ticket_Frequency\"] = train_df.groupby(\"Ticket\")[\"Ticket\"].transform('count')\ntest_df[\"Ticket_Frequency\"] = test_df.groupby(\"Ticket\")[\"Ticket\"].transform('count')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:08:26.746625Z","iopub.execute_input":"2022-09-30T10:08:26.747093Z","iopub.status.idle":"2022-09-30T10:08:26.762736Z","shell.execute_reply.started":"2022-09-30T10:08:26.747047Z","shell.execute_reply":"2022-09-30T10:08:26.761041Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Title & IsMaried\ntrain_df['Title'] = train_df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntrain_df['Is_Maried'] = np.where(train_df[\"Title\"] == 'Mrs', 1,0)\n\ntest_df[\"Title\"] = test_df[\"Name\"].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntest_df[\"Is_Maried\"] = np.where(test_df[\"Title\"] == 'Mrs', 1,0)\n\ntrain_df[\"Title\"] = train_df[\"Title\"].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\ntrain_df[\"Title\"] = train_df[\"Title\"].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'],'Dr/Military/Noble/Clergy')\ntest_df[\"Title\"] = test_df[\"Title\"].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'],'Miss/Mrs/Ms')\ntest_df[\"Title\"] = test_df[\"Title\"].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'],'Dr/Military/Noble/Clergy')","metadata":{"execution":{"iopub.status.busy":"2022-09-30T10:21:39.946452Z","iopub.execute_input":"2022-09-30T10:21:39.946885Z","iopub.status.idle":"2022-09-30T10:21:39.975408Z","shell.execute_reply.started":"2022-09-30T10:21:39.946851Z","shell.execute_reply":"2022-09-30T10:21:39.974432Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}